<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet href="pretty-atom-feed.xsl" type="text/xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <title>Blog Title</title>
  <subtitle>This is a longer description about your blog.</subtitle>
  <link href="https://example.com/blog/feed/feed.xml" rel="self" />
  <link href="https://example.com/blog/" />
  <updated>2023-09-15T00:00:00Z</updated>
  <id>https://example.com/blog/</id>
  <author>
    <name>Your Name</name>
  </author>
  <entry>
    <title>Beginner&#39;s Guide to DFT and ML</title>
    <link href="https://example.com/blog/blog/Beginner&amp;#39;s-Guide-to-DFT-and-ML/" />
    <updated>2023-09-15T00:00:00Z</updated>
    <id>https://example.com/blog/blog/Beginner&amp;#39;s-Guide-to-DFT-and-ML/</id>
    <content type="html">&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/blog/blog/Beginner&#39;s-Guide-to-DFT-and-ML/3AOe9n1L0T-7360.avif 7360w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/blog/blog/Beginner&#39;s-Guide-to-DFT-and-ML/3AOe9n1L0T-7360.webp 7360w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/blog/blog/Beginner&#39;s-Guide-to-DFT-and-ML/3AOe9n1L0T-7360.jpeg&quot; alt=&quot;&quot; width=&quot;7360&quot; height=&quot;4912&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Below are my brief takes on density functional theory and machine learning, accompanied by helpful resources.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;My work leverages computational tools to study porous materials. These tools include &lt;strong&gt;Density Functional Theory (DFT)&lt;/strong&gt; and &lt;strong&gt;Machine Learning (ML)&lt;/strong&gt;. At a high level, DFT allows us to set up several quantum‐mechanical equations. By solving them, we can learn about the electronic properties of a set of atoms with an accuracy that matches experimental measurements. To learn more about DFT, check out &lt;a href=&quot;https://www.youtube.com/channel/UCPtZ0t9Fn2cVETnHqJECW2w&quot;&gt;Rasoul Khaledialidusti&lt;/a&gt;’s four-part &lt;a href=&quot;https://www.youtube.com/playlist?list=PLvZcfmZeLsvrq5kmsBcyFFIozKZR6mJ-s&quot;&gt;series&lt;/a&gt;. A great complement to this series is a &lt;a href=&quot;https://www.youtube.com/playlist?list=PLT-GNiCGT-NRk1nD8fZqZcn0zuCEJ6E0_&quot;&gt;set of lectures&lt;/a&gt; by my PhD advisor, Dr. Ramprasad, on Electronic Structure Theory.&lt;/p&gt;
&lt;p&gt;In addition to the electronic properties, we sometimes wish to understand a material’s &lt;strong&gt;phononic properties&lt;/strong&gt;—that is, the coordinated movement of its atoms. These are uncovered by obtaining the &lt;em&gt;Dynamical Matrix&lt;/em&gt;. To learn more, I recommend this easy-to-digest &lt;a href=&quot;https://www.neutron-sciences.org/articles/sfn/pdf/2011/01/sfn201112007.pdf&quot;&gt;paper&lt;/a&gt; by M.T. Dove. In short, the Dynamical Matrix reveals how displacing one atom affects the forces on the others. (G J Ackland also wrote a nice review of these methods, available &lt;a href=&quot;https://iopscience.iop.org/article/10.1088/0953-8984/14/11/311/pdf&quot;&gt;here&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;Although DFT is incredibly powerful, it can be slow for systems with many atoms. &lt;strong&gt;Machine Learning (ML)&lt;/strong&gt; offers a speedy alternative. An incredible introduction to ML is available in Andrew Ng’s lecture series &lt;a href=&quot;https://www.youtube.com/watch?v=PPLop4L2eGk&amp;amp;list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&quot;&gt;here&lt;/a&gt;. In simple terms, ML is a way to approximate &lt;em&gt;maps&lt;/em&gt;—that is, a set of relationships between inputs and outputs. For example, consider the relationship between numbers and letters as shown in the diagram below:&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/blog/blog/Beginner&#39;s-Guide-to-DFT-and-ML/B6j746M0hu-240.avif 240w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/blog/blog/Beginner&#39;s-Guide-to-DFT-and-ML/B6j746M0hu-240.webp 240w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/blog/blog/Beginner&#39;s-Guide-to-DFT-and-ML/B6j746M0hu-240.png&quot; alt=&quot;&quot; width=&quot;240&quot; height=&quot;240&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;There are many flavors of ML algorithms, each uniquely using data to approximate the underlying map. Perhaps the most popular is the &lt;em&gt;neural network&lt;/em&gt;. With just five minutes and a little Python knowledge, you can create your very own neural network using the Keras API. Check out &lt;a href=&quot;https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/&quot;&gt;this tutorial&lt;/a&gt; for a quick start (remember to set up your environment first). While Keras is easy to get started with, more advanced networks (such as Variational Autoencoders) require a deeper dive. Stanford’s free &lt;a href=&quot;http://web.stanford.edu/class/cs20si/syllabus.html&quot;&gt;lectures&lt;/a&gt; on TensorFlow are an excellent resource, and you can also view &lt;a href=&quot;https://www.youtube.com/watch?v=TFWYoZoezrY&quot;&gt;my lecture&lt;/a&gt; on debugging neural networks.&lt;/p&gt;
&lt;p&gt;Another ML method I frequently use is &lt;em&gt;Gaussian Process Regression (GPR)&lt;/em&gt;. A gentle introduction to GPR is available &lt;a href=&quot;https://towardsdatascience.com/quick-start-to-gaussian-process-regression-36d838810319&quot;&gt;here&lt;/a&gt; (a basic understanding of probability notation helps).&lt;/p&gt;
&lt;h3 id=&quot;share-this&quot;&gt;Share this:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://rishigurnani.wordpress.com/learning/?share=twitter&quot; title=&quot;Click to share on Twitter&quot;&gt;Twitter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://rishigurnani.wordpress.com/learning/?share=facebook&quot; title=&quot;Click to share on Facebook&quot;&gt;Facebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <title>Confessions of a Researcher: How I Found Happiness, Time Efficiency, and Novelty through BLT</title>
    <link href="https://example.com/blog/blog/blt/" />
    <updated>2020-09-04T00:00:00Z</updated>
    <id>https://example.com/blog/blog/blt/</id>
    <content type="html">&lt;p&gt;&lt;picture&gt;&lt;source type=&quot;image/avif&quot; srcset=&quot;https://example.com/blog/blog/blt/WRFmgBRFaF-6000.avif 6000w&quot;&gt;&lt;source type=&quot;image/webp&quot; srcset=&quot;https://example.com/blog/blog/blt/WRFmgBRFaF-6000.webp 6000w&quot;&gt;&lt;img loading=&quot;lazy&quot; decoding=&quot;async&quot; src=&quot;https://example.com/blog/blog/blt/WRFmgBRFaF-6000.jpeg&quot; alt=&quot;&quot; width=&quot;6000&quot; height=&quot;3376&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;Happiness, time, and novel work...pick two out of three if you’re a researcher, right? Maybe not. There &lt;strong&gt;IS&lt;/strong&gt; a way to get all three—and it works for me. While I can’t guarantee it will work for everyone, I’m hoping you and I are similar enough that this strategy might just be your magic bullet too.&lt;/p&gt;
&lt;p&gt;What is this ‘magic bullet’? It’s pretty simple—I call it &lt;strong&gt;blocked learning time&lt;/strong&gt; (BLT). BLT is a strategy where you set aside weekly blocks of time solely dedicated to &lt;em&gt;learning&lt;/em&gt;. By dedicated, I mean you should not be running experiments, analyzing data, conducting a listless literature review, or replying to emails. Your only job during BLT is to read about new fields and topics, reinforce concepts, and think about connections from these new areas to your current work.&lt;/p&gt;
&lt;p&gt;In what follows, I’ll discuss three tangible benefits of BLT—&lt;strong&gt;time efficiency&lt;/strong&gt;, &lt;strong&gt;novelty&lt;/strong&gt;, and &lt;strong&gt;happiness&lt;/strong&gt;—and provide concrete examples from my experience as a computational researcher in the physical sciences.&lt;/p&gt;
&lt;h2 id=&quot;time-efficiency&quot;&gt;Time Efficiency&lt;/h2&gt;
&lt;p&gt;One of the greatest benefits of the computer science community is its commitment to open-source software. Many brilliant developers have packaged their work into easy-to-use libraries that we can leverage to speed up our own tasks. There are two common approaches when using a library:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The “greedy” method: Start with little knowledge of the library, write a buggy script, and fix errors by copying snippets from Professor Google.&lt;/li&gt;
&lt;li&gt;The BLT method: Spend time upfront learning the library’s nuances, then write an efficient script with minor bugs that you can quickly resolve with your newly acquired knowledge.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I encountered this crossroads with &lt;strong&gt;Tensorflow&lt;/strong&gt;. I initially used the greedy method while trying to build a Variational Autoencoder (a fancy neural network model). I copied and pasted code that, while functional, lacked some custom features I needed. After countless hours debugging, I decided to spend some dedicated BLT time with a &lt;a href=&quot;http://web.stanford.edu/class/cs20si/syllabus.html&quot;&gt;free online Stanford course&lt;/a&gt; on Tensorflow. The insights I gained allowed me to write an efficient, custom solution—saving me time and mental energy in the long run.&lt;/p&gt;
&lt;h2 id=&quot;novelty&quot;&gt;Novelty&lt;/h2&gt;
&lt;p&gt;Once you become more time-efficient, you gain extra time to explore new fields. My work in &lt;strong&gt;Computational Polymer Science&lt;/strong&gt;—using computers to study polymers before performing costly experiments—was revolutionized when I read about advances in &lt;strong&gt;Computational Drug Discovery&lt;/strong&gt;. Though these fields focus on different materials, the underlying techniques have a lot in common. By connecting ideas from drug discovery with polymer science, I was able to adapt cutting-edge methods from one field to drive innovation in the other. Although I’m not the most brilliant researcher, my willingness to learn and connect disparate ideas allowed me to pioneer novel approaches in my domain.&lt;/p&gt;
&lt;h2 id=&quot;happiness&quot;&gt;Happiness&lt;/h2&gt;
&lt;p&gt;Increasing time efficiency and injecting novelty into my work have not only enhanced my research but have also made my work-life happier. When you manage your time effectively, you have more freedom to enjoy life outside of work—whether that means binge-watching a limited series on Netflix or simply spending quality time with friends and family.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;That’s BLT—its benefits served up in a neat little bun. Flexibility is key, though. If you have a tight deadline or need to take time off, missing a week of BLT isn’t the end of the world. But if too many weeks pass without dedicated learning time, it might be time to re-evaluate your schedule and take another bite.&lt;/p&gt;
</content>
  </entry>
</feed>